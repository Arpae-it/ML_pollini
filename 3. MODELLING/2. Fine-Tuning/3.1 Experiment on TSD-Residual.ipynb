{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27e9f867",
   "metadata": {},
   "source": [
    "# Experiment on Cluster TSD Residual\n",
    "Notebook to perform some model on a single TSD Residual Cluster: trhougth time-series-decomposition, the residual inside the cluster is extracted and used to make prediction.<br>\n",
    "Data read are from table SLIDING_WINDOWS_DATASET that contains a sliding windows of:\n",
    "- feats about last 7-days meteo values\n",
    "- pollen value for the next day\n",
    "\n",
    "Cluster associations are read from a local file: we have different cluster annotations made by different techniques.<br>\n",
    "We explore different model & hyper-parameters throught Comet ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96a293a",
   "metadata": {},
   "source": [
    "<h3>Import</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80880ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 08:58:33.838963: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.18.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from google.cloud import bigquery\n",
    "\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import get_cmap\n",
    "from matplotlib import cm\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "import scipy.stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "\n",
    "from comet_ml import Experiment\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers.experimental import Adam, AdamW, Adadelta\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "my_cmap = plt.get_cmap(\"Paired\")\n",
    "init_notebook_mode(connected=True)  \n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7c4047",
   "metadata": {},
   "source": [
    "<h3>Config</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7031950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "\n",
    "PROJECT_ID = 'arpae-prod-ml'\n",
    "\n",
    "# BigQuery\n",
    "BQ_DATASET = 'SAMPLE_DATA'\n",
    "JOINED_BQ_DATASET = 'JOINED_DATA'\n",
    "\n",
    "# Const\n",
    "COMMON_PERIOD_INIT = '2011-01-01'\n",
    "COMMON_PERIOD_END = '2023-12-31' \n",
    "\n",
    "TRAIN_END = '2016-12-31 00:00:00+00:00'\n",
    "VAL_END = '2019-12-31 00:00:00+00:00'\n",
    "TEST_END = '2022-12-31 00:00:00+00:00'\n",
    "\n",
    "# Cols\n",
    "DATE_COL = 'date'\n",
    "\n",
    "# Feats\n",
    "METEO_FEATS = ['week_amax', \n",
    "               'station_lat_amax', 'station_lon_amax', 'station_H_piano_strada_amax', 'station_H_mslm_amax', \n",
    "               'B13011_min_amin', 'B13011_max_amax', 'B13011_mean_mean', 'B13011_std_mean', 'B13011_sum_sum', \n",
    "               'B14198_min_amin', 'B14198_max_amax', 'B14198_mean_mean', 'B14198_std_mean', 'B14198_sum_sum',\n",
    "               'TEMP_min_amin', 'TEMP_max_amax', 'TEMP_mean_mean', 'TEMP_std_mean', 'TEMP_sum_sum',                                               \n",
    "               'PREC_amin', 'PREC_mean', 'PREC_std', 'PREC_median', 'PREC_amax', 'PREC_skew', 'PREC_kurtosis']\n",
    "POLLEN_FEATS = ['residual_mean', 'residual_prev_1', # seasonal, trend, residual\n",
    "                'pol_value_amin', 'pol_value_mean', 'pol_value_std', 'pol_value_median', 'pol_value_amax', \n",
    "                'pol_value_skew', 'pol_value_kurtosis',\n",
    "                'pol_value_prev_1', 'pol_value_prev_2', 'pol_value_prev_3',\n",
    "                'pol_value_prev_4', 'pol_value_prev_5', 'pol_value_prev_6',\n",
    "                'pol_value_prev_7']\n",
    "ORIGINAL_FEATS = METEO_FEATS + POLLEN_FEATS\n",
    "LABEL_COL = 'residual_label' # season, trend, residual\n",
    "\n",
    "# Params\n",
    "EPOCHS = 50\n",
    "\n",
    "# Comet Params\n",
    "COMET_API_KEY = 'B4Tttbbx4JrwXD9x2HBNjCdXX'\n",
    "COMET_WORKSPACE = 'pveronesi' \n",
    "COMET_PROJECT_NAME = 'arpae-tsd-residual-experiments' # season, trend, residual\n",
    "\n",
    "# Layout\n",
    "COLOR_PALETTE = px.colors.qualitative.Prism\n",
    "\n",
    "OUTPUT_CLUSTER_FILENAME = \"../../data/clustering_residual_intervals.csv\" # season, trend, residual\n",
    "OPT_PARAMS_FILENAME = \"../../data/optimal_params_residual.csv\" # season, trend, residual\n",
    "MODEL_DIR = \"../../models/residual/\" # season, trend, residual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b40c5c9",
   "metadata": {},
   "source": [
    "<h3>Methods</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb72ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Methods\n",
    "\n",
    "def _run_query(client, query): \n",
    "    df = client.query(query).to_dataframe()\n",
    "    return df\n",
    "\n",
    "def _read_table(client, project_id, dataset, table):\n",
    "    query = \"SELECT * FROM `{}.{}.{}` \".format(project_id, dataset, table)\n",
    "    df = _run_query(client, query)\n",
    "    return df\n",
    "\n",
    "def _read_table_delta(client, project_id, dataset, table, date_col, init, end):\n",
    "    query = \"SELECT * FROM `{}.{}.{}` WHERE {} > '{}' AND {} < '{}' \".format(project_id, dataset, table, date_col, init, date_col, end)\n",
    "    df = _run_query(client, query)\n",
    "    if 'reftime' in df.columns:\n",
    "        df.sort_values(by='reftime', inplace=True)\n",
    "    elif date_col in df.columns:\n",
    "        df.sort_values(by=date_col, inplace=True)\n",
    "    else:\n",
    "        return None\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45dded16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comet methods\n",
    "\n",
    "def _create_experiment(api_key, workspace, project_name):\n",
    "    experiment = Experiment(\n",
    "        # user config\n",
    "        api_key=api_key,\n",
    "        workspace=workspace,  \n",
    "        # project config\n",
    "        project_name=project_name,\n",
    "        # logging config\n",
    "        log_code=True,\n",
    "        log_graph=True,\n",
    "        auto_param_logging=True,\n",
    "        auto_metric_logging=True,    \n",
    "        auto_histogram_weight_logging=True,\n",
    "        auto_histogram_gradient_logging=True,\n",
    "        auto_histogram_activation_logging=True\n",
    "    )\n",
    "    return experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36411aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Methods\n",
    "\n",
    "def _create_experiment_widget():\n",
    "    exp_wdgt = widgets.Dropdown(options=['Opt Params', 'Manual Params'], description='Set Params:', layout={\"width\":\"50%\"})\n",
    "    return exp_wdgt\n",
    "\n",
    "def _create_cluster_widget(clusters):\n",
    "    cluster_wdgt = widgets.Dropdown(options=clusters, description='Cluster id:', layout={\"width\":\"50%\"})\n",
    "    return cluster_wdgt\n",
    "\n",
    "def _normalize(x, range_dict, index_col, label_col):\n",
    "    pol_min = range_dict[x[index_col]]['min']\n",
    "    pol_max = range_dict[x[index_col]]['max']\n",
    "    return (x[label_col] - pol_min) / (pol_max - pol_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37550651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Methods\n",
    "\n",
    "def _get_data(data_df, clusters_df, cluster_id, feats_cols, date_col, label_col):\n",
    "    # filter data\n",
    "    filt_clusters_df = clusters_df[clusters_df['cluster']==cluster_id][['station_id', 'pol_var_id']]\n",
    "    dataset_df = pd.merge(data_df, filt_clusters_df, how='right', on=['station_id', 'pol_var_id'])\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset_df.sort_values(['station_id', 'pol_var_id', date_col], inplace=True)\n",
    "    dataset_df = dataset_df[['station_id', 'pol_var_id', date_col]  + feats_cols + [label_col]]\n",
    "    \n",
    "    # Set index and drop nan\n",
    "    dataset_df.set_index(date_col, inplace=True)\n",
    "    dataset_df.dropna(inplace=True)\n",
    "    \n",
    "    print(\"Rows: {}\".format(dataset_df.shape[0]))\n",
    "    return dataset_df\n",
    "\n",
    "def _prepare_data(dataset_df, original_feats, meteo_feats, pollen_feats, label_col):\n",
    "    # Add 1-hot encoding cols\n",
    "    stations_one_hot = pd.get_dummies(dataset_df['station_id'], prefix='station_id')\n",
    "    pollen_one_hot = pd.get_dummies(dataset_df['pol_var_id'], prefix='pol_var_id')\n",
    "    dataset_df = pd.concat([dataset_df, stations_one_hot], axis=1)\n",
    "    dataset_df = pd.concat([dataset_df, pollen_one_hot], axis=1)\n",
    "    \n",
    "    # Update Features\n",
    "    feats = original_feats + stations_one_hot.columns.values.tolist() + pollen_one_hot.columns.values.tolist()\n",
    "    n_feats = len(feats)\n",
    "    \n",
    "    # Normalize all cols except for pollen ones; Save max cols to restore original values\n",
    "    cols_max = []\n",
    "    for col in meteo_feats:\n",
    "        scaler = MinMaxScaler()\n",
    "        dataset_df[col] = pd.DataFrame(scaler.fit_transform(dataset_df[[col]])).values\n",
    "        cols_max.append(int(scaler.data_max_))\n",
    "\n",
    "    # Normalize with Min-Max scaling each pollen feats \n",
    "    for col in tqdm(pollen_feats):\n",
    "        range_df = dataset_df[['pol_var_id', col]].groupby('pol_var_id').agg(['min', 'max'])\n",
    "        ranges = {}\n",
    "        for index, values in zip(range_df.index, range_df.values):\n",
    "            ranges[index] = {'min': values[0], 'max': values[1]}        \n",
    "        dataset_df[col] = dataset_df.apply(lambda x: _normalize(x, ranges, 'pol_var_id', col), axis=1)    \n",
    "    \n",
    "    # Normalize with Min-Max scaling the label col\n",
    "    range_df = dataset_df[['pol_var_id', LABEL_COL]].groupby('pol_var_id').agg(['min', 'max'])\n",
    "    ranges = {}\n",
    "    for index, values in zip(range_df.index, range_df.values):\n",
    "        ranges[index] = {'min': values[0], 'max': values[1]}        \n",
    "    dataset_df[label_col] = dataset_df.apply(lambda x: _normalize(x, ranges, 'pol_var_id', label_col), axis=1)    \n",
    "    \n",
    "    # Sort data\n",
    "    dataset_df.index = pd.to_datetime(dataset_df.index)\n",
    "    dataset_df.sort_values(by=['station_id', 'pol_var_id', 'date'], inplace=True)\n",
    "\n",
    "    return dataset_df, feats, n_feats, cols_max\n",
    "\n",
    "def _create_datasets(dataset_df, train_end, val_end, test_end, feats, label_col, batch_size):\n",
    "    # Split df into train and test sets\n",
    "    train_df = dataset_df[dataset_df.index < pd.to_datetime(train_end)]\n",
    "    val_df = dataset_df[(dataset_df.index > pd.to_datetime(train_end)) & \n",
    "                        (dataset_df.index < pd.to_datetime(val_end))]\n",
    "    test_df = dataset_df[(dataset_df.index > pd.to_datetime(val_end)) & \n",
    "                         (dataset_df.index < pd.to_datetime(test_end))]\n",
    "    print(\"Train dataset: {}, Val dataset: {}, Test dataset: {}\".format(train_df.shape[0], val_df.shape[0], test_df.shape[0]))\n",
    "    \n",
    "    # Split into feats and labels\n",
    "    train_X, train_y = train_df[feats].values, train_df[label_col]\n",
    "    val_X, val_y = val_df[feats].values, val_df[label_col]\n",
    "    test_X, test_y = test_df[feats].values, test_df[label_col]\n",
    "\n",
    "    # Reshape X-inputs to be 3D for LSTM [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    val_X = val_X.reshape((val_X.shape[0], 1, val_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "    return train_X, train_y, val_X, val_y, test_X, test_y, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab688a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Methods\n",
    "\n",
    "def _attention_base_model(n_feats, dropout, attn_key_dim, layer_dense_1_units, layer_dense_2_units, \n",
    "                          layer_dense_3_units):\n",
    "    input_layer = tf.keras.layers.Input(shape=(1, n_feats))\n",
    "    x = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=attn_key_dim)(query=input_layer, \n",
    "                                                                              value=input_layer, \n",
    "                                                                              key=input_layer)\n",
    "    x = tf.keras.layers.Dense(units=layer_dense_1_units)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(units=layer_dense_2_units)(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    x = tf.keras.layers.Dense(units=layer_dense_3_units)(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    output_layer = tf.keras.layers.Dense(units=1)(x)\n",
    "    model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer) \n",
    "    return model\n",
    "\n",
    "# Losses Methods\n",
    "\n",
    "def _compile_mse_model(model):\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "    model.summary()\n",
    "    return model, early_stop\n",
    "\n",
    "def _compile_adamw_mse_model(model, learning_rate, weight_decay):\n",
    "    # AdamW \n",
    "    optimizer = AdamW(learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "    model.summary()\n",
    "    return model, early_stop\n",
    "\n",
    "def _compile_adadelta_mse_model(model, learning_rate, rho):\n",
    "    # Adadelta is based on adaptive learning rate\n",
    "    optimizer = Adadelta(learning_rate=learning_rate, rho=rho)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "    model.summary()\n",
    "    return model, early_stop\n",
    "\n",
    "# Training Methods\n",
    "\n",
    "def _fit_model(model, epochs, train_X, train_y, val_X, val_y, callbacks):    \n",
    "    history = model.fit(train_X, train_y, \n",
    "                        epochs=epochs,\n",
    "                        validation_data=(val_X, val_y), \n",
    "                        verbose=1, \n",
    "                        callbacks=callbacks,\n",
    "                        shuffle=True)\n",
    "    return history\n",
    "    \n",
    "def _run_experiment(comet_api_key, comet_workspace, comet_project, data_df, clusters_df,\n",
    "                    cluster_id, tag,\n",
    "                    model_name, batch_size, loss, learning_rate, weight_decay, rho, epochs,\n",
    "                    dropout, attn_key_dim, layer_dense_1_units, layer_dense_2_units, layer_dense_3_units,\n",
    "                    original_feats, meteo_feats, pollen_feats, date_col, label_col,\n",
    "                    train_end, val_end, test_end):\n",
    "\n",
    "    model_id = \"{}-Batch{}-Loss{}-Cluster{}\".format(model_name, batch_size, loss, cluster_id)\n",
    "    experiment = _create_experiment(comet_api_key, comet_workspace, comet_project)\n",
    "    experiment.set_name(model_id)\n",
    "    experiment.add_tag(tag)\n",
    "    print(\"Running Experiment {}:\".format(model_id))\n",
    "\n",
    "    # Get Data\n",
    "    print(\"\\nGetting data..\")\n",
    "    dataset_df = _get_data(data_df, clusters_df, cluster_id, original_feats, date_col, label_col)    \n",
    "\n",
    "    # Prepare Data\n",
    "    print(\"\\nPreparing data..\")\n",
    "    dataset_df, feats, n_feats, cols_max = _prepare_data(dataset_df, original_feats, meteo_feats, \n",
    "                                                         pollen_feats, label_col)\n",
    "\n",
    "    # Create Dataset\n",
    "    print(\"\\nCreating dataset..\")\n",
    "    train_X, train_y, val_X, val_y, test_X, test_y, test_df = _create_datasets(dataset_df, train_end, val_end,\n",
    "                                                                               test_end, feats, label_col, \n",
    "                                                                               batch_size)\n",
    "\n",
    "    # Define Model\n",
    "    print(\"\\nDefining & Training model..\")\n",
    "    if model_name == 'Attention_base':\n",
    "        model = _attention_base_model(n_feats, dropout, attn_key_dim, layer_dense_1_units, layer_dense_2_units, \n",
    "                                      layer_dense_3_units)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # Compile Model\n",
    "    if loss == 'ADAM_MSE':\n",
    "        model, early_stop = _compile_mse_model(model)\n",
    "    elif loss == 'ADAMW_MSE':\n",
    "        model, early_stop = _compile_adamw_mse_model(model, learning_rate, weight_decay)\n",
    "    elif loss == 'ADADELTA_MSE':\n",
    "        model, early_stop = _compile_adadelta_mse_model(model, learning_rate, rho)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # Train Model\n",
    "    history = _fit_model(model, epochs, train_X, train_y, val_X, val_y, [early_stop])\n",
    "\n",
    "    # Get Error on test-set\n",
    "    preds, error = _get_error(model, test_X, test_y)\n",
    "    experiment.log_other(\"test-error\", error)\n",
    "    print(\"Final Error: {}\".format(error))\n",
    "    \n",
    "    # Save Model (locally and on comet)\n",
    "    model_path = os.path.join(MODEL_DIR, model_id)\n",
    "    print(\"Saving Model on {} ..\".format(model_path))\n",
    "    model.save(model_path)\n",
    "    experiment.log_model(model_id, model_path)\n",
    "\n",
    "    # End experiment\n",
    "    experiment.end()\n",
    "    \n",
    "    return history, test_X, test_y, test_df, preds, error, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40bde03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Methods\n",
    "\n",
    "def _get_error(model, test_X, test_y):\n",
    "    preds = model.predict(test_X).squeeze()    \n",
    "    error = np.mean(np.abs(preds-test_y))\n",
    "    return preds, error\n",
    "\n",
    "def _feats_importances(test_X, test_y, feats):\n",
    "    # Get baseline error\n",
    "    feats_imp = []\n",
    "    ff_preds = model.predict(test_X, verbose=0).squeeze()\n",
    "    ff_x, ff_y = test_X, test_y\n",
    "    ff_x, ff_y = np.array(ff_x), np.array(ff_y)\n",
    "    baseline_error = np.mean(np.abs(ff_preds-np.array(ff_y)))\n",
    "    feats_imp.append({'feature':'BASELINE','mae': baseline_error})\n",
    "    \n",
    "    # Get features gain on reducing error: each value \n",
    "    for k in tqdm(range(len(feats))):\n",
    "        # Change values for current feat\n",
    "        save_col = ff_x[:,:,k].copy()\n",
    "        ff_x[:,:,k] = -100\n",
    "        # Compute error \n",
    "        oof_preds = model.predict(ff_x, verbose=0).squeeze() \n",
    "        mae = np.mean(np.abs(oof_preds-ff_y))\n",
    "        feats_imp.append({'feature': feats[k],'mae': mae})\n",
    "        ff_x[:,:,k] = save_col\n",
    "    \n",
    "    # Plot \n",
    "    df = pd.DataFrame(feats_imp)\n",
    "    df = df.sort_values('mae')\n",
    "    plt.figure(figsize=(10, 13))\n",
    "    plt.barh(np.arange(len(feats)+1), df.mae)\n",
    "    plt.yticks(np.arange(len(feats)+1), df.feature.values)\n",
    "    plt.title('LSTM Feature Importance', size=16)\n",
    "    plt.ylim((-1, len(feats)+1))\n",
    "    plt.plot([baseline_error, baseline_error], [-1,len(feats)+1], '--', color='orange',\n",
    "             label=f'Baseline OOF\\nMAE={baseline_error:.3f}')\n",
    "    plt.xlabel('MAE with feature permuted', size=14)\n",
    "    plt.ylabel('Feature', size=14)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def _plot_history(history):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def _plot_preds(preds, test_df, label_col):\n",
    "    # Preds\n",
    "    for i in range(len(preds), test_df.shape[0]):\n",
    "        preds = np.append(preds, 0.0)\n",
    "    test_df['preds'] = preds\n",
    "    # Plot some station & bcode\n",
    "    N_SAMPLE = 10\n",
    "    for station_id, pol_var_id in test_df[['station_id', 'pol_var_id']].drop_duplicates().sample(N_SAMPLE).values:\n",
    "        curr_test_df = test_df[(test_df['station_id']==station_id) & (test_df['pol_var_id']==pol_var_id)]\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.title(\"{} - {}\".format(station_id, pol_var_id))\n",
    "        plt.plot(curr_test_df.index, curr_test_df['preds'], label='pred')\n",
    "        plt.plot(curr_test_df.index, curr_test_df[label_col], label='truth')\n",
    "        plt.legend()\n",
    "        plt.ylim(0, 1)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02294648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3b476b0",
   "metadata": {},
   "source": [
    "<h3>1. Config</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8487293b",
   "metadata": {},
   "source": [
    "<h4>1.1 Config BigQuery</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d526cc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.client.Client at 0x15c117f40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup Client\n",
    "\n",
    "bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "bq_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5ae261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e6b9aa3",
   "metadata": {},
   "source": [
    "<h3>2. Read Data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185c05b0",
   "metadata": {},
   "source": [
    "<h4>2.1 Read Cluster file</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fac3602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(363, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>pol_var_id</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B48001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>B48002</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>B48003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id pol_var_id  cluster\n",
       "0           1     B48001        1\n",
       "1           1     B48002        5\n",
       "2           1     B48003        0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_df = pd.read_csv(OUTPUT_CLUSTER_FILENAME)\n",
    "print(clusters_df.shape)\n",
    "clusters_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42672b51",
   "metadata": {},
   "source": [
    "<h4>2.2 Read Optimal Params (if setted)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91f53b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>exp_id</th>\n",
       "      <th>attention_key_dim</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>layer_dense_1_units</th>\n",
       "      <th>layer_dense_2_units</th>\n",
       "      <th>layer_dense_3_units</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Attention_base</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Attention_base</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>0.1</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Attention_base</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>0.1</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.0068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Attention_base</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0603</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Attention_base</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8</td>\n",
       "      <td>512</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>0.0177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Attention_base</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>0.1</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Attention_base</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>0.4</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0777</td>\n",
       "      <td>0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Attention_base</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>0.7</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Attention_base</td>\n",
       "      <td>7</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>0.6</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Attention_base</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.2</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_id      model_name  exp_id  attention_key_dim  batch_size  dropout  \\\n",
       "0           0  Attention_base       8                 64         256      0.3   \n",
       "1           1  Attention_base       5                128         256      0.1   \n",
       "2           2  Attention_base       8                128         512      0.1   \n",
       "3           3  Attention_base       8                 64         256      0.3   \n",
       "4           4  Attention_base       2                128         256      0.8   \n",
       "5           5  Attention_base       8                 64         512      0.1   \n",
       "6           6  Attention_base       8                 64         256      0.4   \n",
       "7           7  Attention_base       5                 64         512      0.7   \n",
       "8           8  Attention_base       7                128         256      0.6   \n",
       "9           9  Attention_base      10                128        1024      0.2   \n",
       "\n",
       "   layer_dense_1_units  layer_dense_2_units  layer_dense_3_units  \\\n",
       "0                  256                   64                  128   \n",
       "1                  256                  256                  256   \n",
       "2                  512                  256                  256   \n",
       "3                   64                  512                  128   \n",
       "4                  512                   64                  128   \n",
       "5                  512                  512                  512   \n",
       "6                  128                  256                  256   \n",
       "7                  128                  256                  512   \n",
       "8                   64                  128                   64   \n",
       "9                   64                  128                  512   \n",
       "\n",
       "   learning_rate  test_error  \n",
       "0         0.0480      0.0046  \n",
       "1         0.0629      0.0160  \n",
       "2         0.0295      0.0068  \n",
       "3         0.0603      0.0000  \n",
       "4         0.0636      0.0177  \n",
       "5         0.0194      0.0062  \n",
       "6         0.0777      0.0150  \n",
       "7         0.0097      0.0160  \n",
       "8         0.0143      0.0078  \n",
       "9         0.0564      0.0000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(OPT_PARAMS_FILENAME):\n",
    "    print(\"Params File Not Found.\")    \n",
    "\n",
    "params_df = pd.read_csv(OPT_PARAMS_FILENAME)\n",
    "print(params_df.shape)\n",
    "params_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b74ed53",
   "metadata": {},
   "source": [
    "<h4>2.2 Read Tables</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d44bb4",
   "metadata": {},
   "source": [
    "<b>SLIDING_WINDOWS_DATASET</b> joins meteo features of last 7-days with the next-day pollen value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6e59922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(826748, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station_id</th>\n",
       "      <th>pol_var_id</th>\n",
       "      <th>date_diff</th>\n",
       "      <th>B13011_min_amin</th>\n",
       "      <th>B13011_max_amax</th>\n",
       "      <th>B13011_mean_mean</th>\n",
       "      <th>B13011_std_mean</th>\n",
       "      <th>B13011_sum_sum</th>\n",
       "      <th>B14198_min_amin</th>\n",
       "      <th>...</th>\n",
       "      <th>pol_var_id_B48033</th>\n",
       "      <th>pol_var_id_B48034</th>\n",
       "      <th>pol_var_id_B48036</th>\n",
       "      <th>pol_var_id_B48037</th>\n",
       "      <th>pol_var_id_B48038</th>\n",
       "      <th>pol_var_id_B48039</th>\n",
       "      <th>pol_var_id_B48041</th>\n",
       "      <th>pol_var_id_B48044</th>\n",
       "      <th>pol_var_id_B48045</th>\n",
       "      <th>WHICH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>325156</th>\n",
       "      <td>2011-01-02 00:00:00+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>B48008</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>0.108532</td>\n",
       "      <td>13.4</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314359</th>\n",
       "      <td>2011-01-02 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>B48034</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.014790</td>\n",
       "      <td>0.148225</td>\n",
       "      <td>17.6</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590215</th>\n",
       "      <td>2011-01-02 00:00:00+00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>B48003</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>0.039220</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             date  station_id pol_var_id  date_diff  \\\n",
       "325156  2011-01-02 00:00:00+00:00           2     B48008         15   \n",
       "314359  2011-01-02 00:00:00+00:00           1     B48034          7   \n",
       "590215  2011-01-02 00:00:00+00:00          13     B48003         10   \n",
       "\n",
       "        B13011_min_amin  B13011_max_amax  B13011_mean_mean  B13011_std_mean  \\\n",
       "325156              0.0              8.8          0.011261         0.108532   \n",
       "314359              0.0             12.6          0.014790         0.148225   \n",
       "590215              0.0              2.4          0.004450         0.039220   \n",
       "\n",
       "        B13011_sum_sum  B14198_min_amin  ...  pol_var_id_B48033  \\\n",
       "325156            13.4            -10.0  ...                  0   \n",
       "314359            17.6             -9.0  ...                  0   \n",
       "590215             3.8             -8.0  ...                  0   \n",
       "\n",
       "        pol_var_id_B48034  pol_var_id_B48036  pol_var_id_B48037  \\\n",
       "325156                  0                  0                  0   \n",
       "314359                  1                  0                  0   \n",
       "590215                  0                  0                  0   \n",
       "\n",
       "        pol_var_id_B48038  pol_var_id_B48039  pol_var_id_B48041  \\\n",
       "325156                  0                  0                  0   \n",
       "314359                  0                  0                  0   \n",
       "590215                  0                  0                  0   \n",
       "\n",
       "        pol_var_id_B48044  pol_var_id_B48045     WHICH  \n",
       "325156                  0                  0  training  \n",
       "314359                  0                  0  training  \n",
       "590215                  0                  0  training  \n",
       "\n",
       "[3 rows x 100 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read SLIDING_WINDOWS_DATASET\n",
    "\n",
    "sliding_windows_dataset_df = _read_table_delta(bq_client, PROJECT_ID, JOINED_BQ_DATASET, \n",
    "                                               \"SLIDING_WINDOWS_DATASET\", \"date\",\n",
    "                                               COMMON_PERIOD_INIT, COMMON_PERIOD_END)\n",
    "sliding_windows_dataset_df['date'] = sliding_windows_dataset_df['date'].astype(\"str\")\n",
    "print(sliding_windows_dataset_df.shape)\n",
    "sliding_windows_dataset_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c87666c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6270912c",
   "metadata": {},
   "source": [
    "<h3>3. Run Experiment</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba676c3",
   "metadata": {},
   "source": [
    "<h4>3.1 Config Experiment</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0ac024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data\n",
    "\n",
    "data_df = sliding_windows_dataset_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6c9d447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 clusters in data\n"
     ]
    }
   ],
   "source": [
    "# Get Clusters\n",
    "\n",
    "clusters = sorted(clusters_df.cluster.unique())\n",
    "print(\"Found {} clusters in data\".format(len(clusters)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08524cfb",
   "metadata": {},
   "source": [
    "<h4>3.2 Set Params</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578fb1e8",
   "metadata": {},
   "source": [
    "Set:\n",
    "- <b>Manual Params</b>: to use the params setted in the code\n",
    "- <b>Opt Params</b>: to read the optimal params from the output file after hyper-params tuning has run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf8c012c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a9d45f2aa349a5bd75928bed44be4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Set Params:', layout=Layout(width='50%'), options=('Opt Params', 'Manual Params'), value…"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set Params\n",
    "\n",
    "exp_wdgt_value = _create_experiment_widget()\n",
    "exp_wdgt_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e13092",
   "metadata": {},
   "source": [
    "<h4>3.3 Run Experiment</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbec03a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default params\n",
    "\n",
    "DEFAULT_CLUSTER_ID = 4\n",
    "DEFAULT_BATCH_SIZE = 512              \n",
    "DEFAULT_LEARNING_RATE = 0.001\n",
    "DEFAULT_WEIGHT_DECAY = 0.004\n",
    "DEFAULT_RHO = 0.95\n",
    "DEFAULT_EPOCHS = 50\n",
    "DEFAULT_MODEL_NAME = 'Attention_base'  # Attention_base\n",
    "DEFAULT_LOSS = 'ADAM_MSE'              # ADAM_MSE, ADAMW_MSE, ADADELTA_MSE\n",
    "\n",
    "DEFAULT_DROPOUT = 0.4\n",
    "DEFAULT_ATTN_KEY_DIM = 64\n",
    "DEFAULT_LAYER_DENSE_1_UNITS = 64\n",
    "DEFAULT_LAYER_DENSE_2_UNITS = 128\n",
    "DEFAULT_LAYER_DENSE_3_UNITS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbdf53c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cluster_id: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/69d32759d9714d159f9e8139085dd0fb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Experiment Attention_base-Batch256-LossADAM_MSE-Cluster0:\n",
      "\n",
      "Getting data..\n",
      "Rows: 85679\n",
      "\n",
      "Preparing data..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1d73cd289940869c678a4efae4b650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating dataset..\n",
      "Train dataset: 52253, Val dataset: 22643, Test dataset: 10746\n",
      "\n",
      "Defining & Training model..\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1, 61)]      0           []                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 09:12:52.090109: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " multi_head_attention (MultiHea  (None, 1, 61)       126525      ['input_1[0][0]',                \n",
      " dAttention)                                                      'input_1[0][0]',                \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 256)       15872       ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 256)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           16448       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          8320        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            129         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 167,294\n",
      "Trainable params: 167,294\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Ignoring automatic log_parameter('verbose') because 'keras:verbose' is in COMET_LOGGING_PARAMETERS_IGNORE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1633/1633 [==============================] - 11s 5ms/step - loss: 0.0013 - val_loss: 5.6655e-04\n",
      "Epoch 2/50\n",
      "1633/1633 [==============================] - 9s 5ms/step - loss: 6.0725e-04 - val_loss: 4.4390e-04\n",
      "Epoch 3/50\n",
      "1633/1633 [==============================] - 8s 5ms/step - loss: 5.1406e-04 - val_loss: 7.5076e-04\n",
      "Epoch 4/50\n",
      "1633/1633 [==============================] - 8s 5ms/step - loss: 4.9139e-04 - val_loss: 5.5524e-04\n",
      "Epoch 5/50\n",
      "1633/1633 [==============================] - 8s 5ms/step - loss: 4.8769e-04 - val_loss: 4.2806e-04\n",
      "Epoch 6/50\n",
      "1633/1633 [==============================] - 8s 5ms/step - loss: 5.0959e-04 - val_loss: 8.2863e-04\n",
      "Epoch 7/50\n",
      "1633/1633 [==============================] - 8s 5ms/step - loss: 4.6971e-04 - val_loss: 4.3867e-04\n",
      "Epoch 8/50\n",
      "1633/1633 [==============================] - 16s 10ms/step - loss: 4.8264e-04 - val_loss: 4.7272e-04\n",
      "Epoch 9/50\n",
      "1633/1633 [==============================] - 18s 11ms/step - loss: 4.4352e-04 - val_loss: 4.3725e-04\n",
      "Epoch 10/50\n",
      "1633/1633 [==============================] - 20s 12ms/step - loss: 4.6921e-04 - val_loss: 6.0733e-04\n",
      "Epoch 11/50\n",
      "1633/1633 [==============================] - 15s 9ms/step - loss: 4.4847e-04 - val_loss: 6.3453e-04\n",
      "Epoch 12/50\n",
      "1633/1633 [==============================] - 16s 10ms/step - loss: 4.4344e-04 - val_loss: 4.2970e-04\n",
      "Epoch 13/50\n",
      "1633/1633 [==============================] - 16s 10ms/step - loss: 4.4667e-04 - val_loss: 5.2448e-04\n",
      "Epoch 14/50\n",
      "1633/1633 [==============================] - 14s 9ms/step - loss: 4.2649e-04 - val_loss: 5.5496e-04\n",
      "Epoch 15/50\n",
      "1633/1633 [==============================] - 15s 9ms/step - loss: 4.3340e-04 - val_loss: 4.1369e-04\n",
      "Epoch 16/50\n",
      "1633/1633 [==============================] - 14s 9ms/step - loss: 4.4052e-04 - val_loss: 4.3542e-04\n",
      "Epoch 17/50\n",
      "1633/1633 [==============================] - 14s 9ms/step - loss: 4.1632e-04 - val_loss: 5.0464e-04\n",
      "Epoch 18/50\n",
      "1633/1633 [==============================] - 12s 7ms/step - loss: 4.2148e-04 - val_loss: 4.2184e-04\n",
      "Epoch 19/50\n",
      "1633/1633 [==============================] - 12s 7ms/step - loss: 4.1764e-04 - val_loss: 4.6432e-04\n",
      "Epoch 20/50\n",
      "1633/1633 [==============================] - 11s 6ms/step - loss: 4.4695e-04 - val_loss: 4.1218e-04\n",
      "Epoch 21/50\n",
      "1633/1633 [==============================] - 12s 7ms/step - loss: 4.2131e-04 - val_loss: 4.3474e-04\n",
      "Epoch 22/50\n",
      "1633/1633 [==============================] - 11s 7ms/step - loss: 3.9966e-04 - val_loss: 5.3728e-04\n",
      "Epoch 23/50\n",
      "1633/1633 [==============================] - 11s 7ms/step - loss: 4.1964e-04 - val_loss: 4.4695e-04\n",
      "Epoch 24/50\n",
      "1633/1633 [==============================] - 10s 6ms/step - loss: 4.2898e-04 - val_loss: 4.4473e-04\n",
      "Epoch 25/50\n",
      "1633/1633 [==============================] - 12s 7ms/step - loss: 4.0063e-04 - val_loss: 4.3800e-04\n",
      "Epoch 26/50\n",
      "1633/1633 [==============================] - 13s 8ms/step - loss: 4.0800e-04 - val_loss: 4.4874e-04\n",
      "Epoch 27/50\n",
      "1633/1633 [==============================] - 12s 8ms/step - loss: 4.2276e-04 - val_loss: 6.9278e-04\n",
      "Epoch 28/50\n",
      "1633/1633 [==============================] - 11s 7ms/step - loss: 4.1245e-04 - val_loss: 4.1994e-04\n",
      "Epoch 29/50\n",
      "1633/1633 [==============================] - 9s 6ms/step - loss: 4.3490e-04 - val_loss: 4.1414e-04\n",
      "Epoch 30/50\n",
      "1629/1633 [============================>.] - ETA: 0s - loss: 4.0440e-04Restoring model weights from the end of the best epoch: 20.\n",
      "1633/1633 [==============================] - 9s 6ms/step - loss: 4.0540e-04 - val_loss: 6.3000e-04\n",
      "Epoch 30: early stopping\n",
      "336/336 [==============================] - 1s 2ms/step\n",
      "Final Error: 0.005795011985895561\n",
      "Saving Model on ../../models/residual/Attention_base-Batch256-LossADAM_MSE-Cluster0 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch256-LossADAM_MSE-Cluster0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch256-LossADAM_MSE-Cluster0/assets\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/69d32759d9714d159f9e8139085dd0fb\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     batch_loss [4920]          : (5.704975774278864e-05, 0.03264341130852699)\n",
      "COMET INFO:     epoch_duration [30]        : (7.495326478000152, 19.845544517000008)\n",
      "COMET INFO:     loss [30]                  : (0.0003996611339971423, 0.00129334453959018)\n",
      "COMET INFO:     val_loss [30]              : (0.00041218011756427586, 0.0008286266820505261)\n",
      "COMET INFO:     validate_batch_loss [2130] : (2.3568240976601373e-06, 0.0013990906300023198)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Name             : Attention_base-Batch256-LossADAM_MSE-Cluster0\n",
      "COMET INFO:     test-error       : 0.005795011985895561\n",
      "COMET INFO:     trainable_params : 167294\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad                 : False\n",
      "COMET INFO:     Adam_beta_1                  : 0.9\n",
      "COMET INFO:     Adam_beta_2                  : 0.999\n",
      "COMET INFO:     Adam_clipnorm                : 1\n",
      "COMET INFO:     Adam_clipvalue               : 1\n",
      "COMET INFO:     Adam_ema_momentum            : 0.99\n",
      "COMET INFO:     Adam_ema_overwrite_frequency : 1\n",
      "COMET INFO:     Adam_epsilon                 : 1e-07\n",
      "COMET INFO:     Adam_global_clipnorm         : 1\n",
      "COMET INFO:     Adam_is_legacy_optimizer     : False\n",
      "COMET INFO:     Adam_jit_compile             : False\n",
      "COMET INFO:     Adam_learning_rate           : 0.0010000000474974513\n",
      "COMET INFO:     Adam_name                    : Adam\n",
      "COMET INFO:     Adam_use_ema                 : False\n",
      "COMET INFO:     Adam_weight_decay            : 1\n",
      "COMET INFO:     epochs                       : 50\n",
      "COMET INFO:     steps                        : 1633\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (245.06 KB)\n",
      "COMET INFO:     histogram3d              : 589\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     model-element            : 5 (2.19 MB)\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: \n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish uploading collected data\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Running Cluster_id: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/b1cb8d066cb44fd4b14b040391163be2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Experiment Attention_base-Batch256-LossADAM_MSE-Cluster1:\n",
      "\n",
      "Getting data..\n",
      "Rows: 70294\n",
      "\n",
      "Preparing data..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006b81c5e1b544d3802c5dae7d12a0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating dataset..\n",
      "Train dataset: 41851, Val dataset: 18802, Test dataset: 9641\n",
      "\n",
      "Defining & Training model..\n",
      "Model: \"model_32\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 1, 59)]      0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 1, 59)       244795      ['input_2[0][0]',                \n",
      " eadAttention)                                                    'input_2[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1, 256)       15360       ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 256)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 256)          65792       ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 256)          0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 256)          65792       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 256)          0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            257         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 391,996\n",
      "Trainable params: 391,996\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "1308/1308 [==============================] - 11s 7ms/step - loss: 0.0032 - val_loss: 9.4370e-04\n",
      "Epoch 2/50\n",
      "1308/1308 [==============================] - 10s 8ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 3/50\n",
      "1308/1308 [==============================] - 10s 8ms/step - loss: 0.0016 - val_loss: 9.5097e-04\n",
      "Epoch 4/50\n",
      "1308/1308 [==============================] - 10s 8ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 5/50\n",
      "1308/1308 [==============================] - 10s 8ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 6/50\n",
      "1308/1308 [==============================] - 11s 8ms/step - loss: 0.0014 - val_loss: 9.3810e-04\n",
      "Epoch 7/50\n",
      "1308/1308 [==============================] - 10s 8ms/step - loss: 0.0014 - val_loss: 9.9602e-04\n",
      "Epoch 8/50\n",
      "1308/1308 [==============================] - 10s 8ms/step - loss: 0.0013 - val_loss: 9.1431e-04\n",
      "Epoch 9/50\n",
      "1308/1308 [==============================] - 11s 8ms/step - loss: 0.0013 - val_loss: 9.1962e-04\n",
      "Epoch 10/50\n",
      "1308/1308 [==============================] - 10s 8ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 11/50\n",
      "1308/1308 [==============================] - 11s 8ms/step - loss: 0.0013 - val_loss: 9.3413e-04\n",
      "Epoch 12/50\n",
      "1308/1308 [==============================] - 11s 8ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 13/50\n",
      "1308/1308 [==============================] - 12s 9ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 14/50\n",
      "1308/1308 [==============================] - 16s 12ms/step - loss: 0.0013 - val_loss: 8.7068e-04\n",
      "Epoch 15/50\n",
      "1308/1308 [==============================] - 16s 12ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 16/50\n",
      "1308/1308 [==============================] - 15s 12ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 17/50\n",
      "1308/1308 [==============================] - 15s 12ms/step - loss: 0.0013 - val_loss: 8.9365e-04\n",
      "Epoch 18/50\n",
      "1308/1308 [==============================] - 16s 12ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 19/50\n",
      "1308/1308 [==============================] - 16s 13ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 20/50\n",
      "1308/1308 [==============================] - 17s 13ms/step - loss: 0.0013 - val_loss: 8.9362e-04\n",
      "Epoch 21/50\n",
      "1308/1308 [==============================] - 17s 13ms/step - loss: 0.0013 - val_loss: 9.7189e-04\n",
      "Epoch 22/50\n",
      "1308/1308 [==============================] - 17s 13ms/step - loss: 0.0013 - val_loss: 9.2917e-04\n",
      "Epoch 23/50\n",
      "1308/1308 [==============================] - 18s 14ms/step - loss: 0.0012 - val_loss: 9.6708e-04\n",
      "Epoch 24/50\n",
      "1308/1308 [==============================] - ETA: 0s - loss: 0.0014Restoring model weights from the end of the best epoch: 14.\n",
      "1308/1308 [==============================] - 21s 16ms/step - loss: 0.0014 - val_loss: 9.4223e-04\n",
      "Epoch 24: early stopping\n",
      "302/302 [==============================] - 1s 3ms/step\n",
      "Final Error: 0.015974410072127097\n",
      "Saving Model on ../../models/residual/Attention_base-Batch256-LossADAM_MSE-Cluster1 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch256-LossADAM_MSE-Cluster1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch256-LossADAM_MSE-Cluster1/assets\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/b1cb8d066cb44fd4b14b040391163be2\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     batch_loss [3144]          : (0.00020289429812692106, 0.1264563649892807)\n",
      "COMET INFO:     epoch_duration [24]        : (10.11433329600004, 21.250933099999656)\n",
      "COMET INFO:     loss [24]                  : (0.0012370445765554905, 0.0032442940864712)\n",
      "COMET INFO:     val_loss [24]              : (0.0008706797962076962, 0.0014254057314246893)\n",
      "COMET INFO:     validate_batch_loss [1416] : (1.3526248949347064e-05, 0.0016861489275470376)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Name             : Attention_base-Batch256-LossADAM_MSE-Cluster1\n",
      "COMET INFO:     test-error       : 0.015974410072127097\n",
      "COMET INFO:     trainable_params : 391996\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad                 : False\n",
      "COMET INFO:     Adam_beta_1                  : 0.9\n",
      "COMET INFO:     Adam_beta_2                  : 0.999\n",
      "COMET INFO:     Adam_clipnorm                : 1\n",
      "COMET INFO:     Adam_clipvalue               : 1\n",
      "COMET INFO:     Adam_ema_momentum            : 0.99\n",
      "COMET INFO:     Adam_ema_overwrite_frequency : 1\n",
      "COMET INFO:     Adam_epsilon                 : 1e-07\n",
      "COMET INFO:     Adam_global_clipnorm         : 1\n",
      "COMET INFO:     Adam_is_legacy_optimizer     : False\n",
      "COMET INFO:     Adam_jit_compile             : False\n",
      "COMET INFO:     Adam_learning_rate           : 0.0010000000474974513\n",
      "COMET INFO:     Adam_name                    : Adam\n",
      "COMET INFO:     Adam_use_ema                 : False\n",
      "COMET INFO:     Adam_weight_decay            : 1\n",
      "COMET INFO:     epochs                       : 50\n",
      "COMET INFO:     steps                        : 1308\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (254.07 KB)\n",
      "COMET INFO:     histogram3d              : 475\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     model-element            : 5 (4.77 MB)\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: \n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Running Cluster_id: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/f3663d470d2e4445af624ddfa4a54d1c\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Experiment Attention_base-Batch512-LossADAM_MSE-Cluster2:\n",
      "\n",
      "Getting data..\n",
      "Rows: 78135\n",
      "\n",
      "Preparing data..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd2b835d5094c109c90a071795d7259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating dataset..\n",
      "Train dataset: 47771, Val dataset: 20209, Test dataset: 10155\n",
      "\n",
      "Defining & Training model..\n",
      "Model: \"model_58\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 1, 58)]      0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 1, 58)       240698      ['input_3[0][0]',                \n",
      " eadAttention)                                                    'input_3[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1, 512)       30208       ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 512)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 256)          131328      ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 256)          0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 256)          65792       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 256)          0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 1)            257         ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 468,283\n",
      "Trainable params: 468,283\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "1493/1493 [==============================] - 16s 10ms/step - loss: 0.0013 - val_loss: 9.3607e-04\n",
      "Epoch 2/50\n",
      "1493/1493 [==============================] - 15s 10ms/step - loss: 6.7863e-04 - val_loss: 0.0011\n",
      "Epoch 3/50\n",
      "1493/1493 [==============================] - 15s 10ms/step - loss: 5.6256e-04 - val_loss: 5.8760e-04\n",
      "Epoch 4/50\n",
      "1493/1493 [==============================] - 15s 10ms/step - loss: 5.5993e-04 - val_loss: 6.5837e-04\n",
      "Epoch 5/50\n",
      "1493/1493 [==============================] - 15s 10ms/step - loss: 5.4240e-04 - val_loss: 0.0011\n",
      "Epoch 6/50\n",
      "1493/1493 [==============================] - 15s 10ms/step - loss: 5.1431e-04 - val_loss: 7.7774e-04\n",
      "Epoch 7/50\n",
      "1493/1493 [==============================] - 15s 10ms/step - loss: 4.9623e-04 - val_loss: 9.0852e-04\n",
      "Epoch 8/50\n",
      "1493/1493 [==============================] - 15s 10ms/step - loss: 4.9971e-04 - val_loss: 6.9282e-04\n",
      "Epoch 9/50\n",
      "1493/1493 [==============================] - 15s 10ms/step - loss: 4.6186e-04 - val_loss: 5.7780e-04\n",
      "Epoch 10/50\n",
      "1493/1493 [==============================] - 15s 10ms/step - loss: 4.3989e-04 - val_loss: 5.6079e-04\n",
      "Epoch 11/50\n",
      "1493/1493 [==============================] - 15s 10ms/step - loss: 4.5306e-04 - val_loss: 5.7693e-04\n",
      "Epoch 12/50\n",
      "1493/1493 [==============================] - 15s 10ms/step - loss: 0.0026 - val_loss: 6.5446e-04\n",
      "Epoch 13/50\n",
      "1493/1493 [==============================] - 15s 10ms/step - loss: 4.2504e-04 - val_loss: 5.5775e-04\n",
      "Epoch 14/50\n",
      "1493/1493 [==============================] - 15s 10ms/step - loss: 4.0254e-04 - val_loss: 5.5842e-04\n",
      "Epoch 15/50\n",
      "1493/1493 [==============================] - 15s 10ms/step - loss: 4.0921e-04 - val_loss: 5.6391e-04\n",
      "Epoch 16/50\n",
      "1493/1493 [==============================] - 15s 10ms/step - loss: 4.2753e-04 - val_loss: 5.6157e-04\n",
      "Epoch 17/50\n",
      "1493/1493 [==============================] - 15s 10ms/step - loss: 4.3820e-04 - val_loss: 5.7344e-04\n",
      "Epoch 18/50\n",
      "1493/1493 [==============================] - 15s 10ms/step - loss: 4.2977e-04 - val_loss: 5.6310e-04\n",
      "Epoch 19/50\n",
      "1493/1493 [==============================] - 15s 10ms/step - loss: 0.0010 - val_loss: 5.5796e-04\n",
      "Epoch 20/50\n",
      "1493/1493 [==============================] - 17s 11ms/step - loss: 4.1600e-04 - val_loss: 5.6871e-04\n",
      "Epoch 21/50\n",
      "1493/1493 [==============================] - 24s 16ms/step - loss: 4.1088e-04 - val_loss: 6.4948e-04\n",
      "Epoch 22/50\n",
      "1493/1493 [==============================] - 24s 16ms/step - loss: 4.3472e-04 - val_loss: 5.9076e-04\n",
      "Epoch 23/50\n",
      "1490/1493 [============================>.] - ETA: 0s - loss: 4.3811e-04Restoring model weights from the end of the best epoch: 13.\n",
      "1493/1493 [==============================] - 27s 18ms/step - loss: 4.3818e-04 - val_loss: 5.6081e-04\n",
      "Epoch 23: early stopping\n",
      "318/318 [==============================] - 2s 5ms/step\n",
      "Final Error: 0.008238143925259392\n",
      "Saving Model on ../../models/residual/Attention_base-Batch512-LossADAM_MSE-Cluster2 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch512-LossADAM_MSE-Cluster2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch512-LossADAM_MSE-Cluster2/assets\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/f3663d470d2e4445af624ddfa4a54d1c\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     batch_loss [3450]          : (3.576297240215354e-05, 0.06728959828615189)\n",
      "COMET INFO:     epoch_duration [23]        : (14.29534860099966, 26.65903537200029)\n",
      "COMET INFO:     loss [23]                  : (0.0004025391535833478, 0.0025525272358208895)\n",
      "COMET INFO:     val_loss [23]              : (0.000557754363398999, 0.0011426840210333467)\n",
      "COMET INFO:     validate_batch_loss [1472] : (3.5251377994427457e-06, 0.0021667180117219687)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Name             : Attention_base-Batch512-LossADAM_MSE-Cluster2\n",
      "COMET INFO:     test-error       : 0.008238143925259392\n",
      "COMET INFO:     trainable_params : 468283\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad                 : False\n",
      "COMET INFO:     Adam_beta_1                  : 0.9\n",
      "COMET INFO:     Adam_beta_2                  : 0.999\n",
      "COMET INFO:     Adam_clipnorm                : 1\n",
      "COMET INFO:     Adam_clipvalue               : 1\n",
      "COMET INFO:     Adam_ema_momentum            : 0.99\n",
      "COMET INFO:     Adam_ema_overwrite_frequency : 1\n",
      "COMET INFO:     Adam_epsilon                 : 1e-07\n",
      "COMET INFO:     Adam_global_clipnorm         : 1\n",
      "COMET INFO:     Adam_is_legacy_optimizer     : False\n",
      "COMET INFO:     Adam_jit_compile             : False\n",
      "COMET INFO:     Adam_learning_rate           : 0.0010000000474974513\n",
      "COMET INFO:     Adam_name                    : Adam\n",
      "COMET INFO:     Adam_use_ema                 : False\n",
      "COMET INFO:     Adam_weight_decay            : 1\n",
      "COMET INFO:     epochs                       : 50\n",
      "COMET INFO:     steps                        : 1493\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (266.72 KB)\n",
      "COMET INFO:     histogram3d              : 456\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     model-element            : 5 (5.64 MB)\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: \n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Running Cluster_id: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/c2032ed5d0b940bf9eca684528f56536\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Experiment Attention_base-Batch256-LossADAM_MSE-Cluster3:\n",
      "\n",
      "Getting data..\n",
      "Rows: 140605\n",
      "\n",
      "Preparing data..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc6ec5fbee94ba7a93cf77e47c5e962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating dataset..\n",
      "Train dataset: 85368, Val dataset: 36856, Test dataset: 18381\n",
      "\n",
      "Defining & Training model..\n",
      "Model: \"model_83\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 1, 66)]      0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 1, 66)       136770      ['input_4[0][0]',                \n",
      " eadAttention)                                                    'input_4[0][0]',                \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 1, 64)        4288        ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 64)           0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 512)          33280       ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 512)          0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 128)          65664       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 128)          0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 1)            129         ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 240,131\n",
      "Trainable params: 240,131\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "2662/2668 [============================>.] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2668/2668 [==============================] - 23s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "2664/2668 [============================>.] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2668/2668 [==============================] - 22s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "2662/2668 [============================>.] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2668/2668 [==============================] - 20s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "2661/2668 [============================>.] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2668/2668 [==============================] - 19s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "2661/2668 [============================>.] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2668/2668 [==============================] - 23s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "2666/2668 [============================>.] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2668/2668 [==============================] - 24s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "2668/2668 [==============================] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2668/2668 [==============================] - 23s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "2666/2668 [============================>.] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2668/2668 [==============================] - 22s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "2660/2668 [============================>.] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2668/2668 [==============================] - 19s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "2668/2668 [==============================] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2668/2668 [==============================] - 24s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "575/575 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET ERROR: Error sending log other messages, got 400 b'{\"msg\":\"Invalid json format: Non-standard token \\'NaN\\': enable `JsonReadFeature.ALLOW_NON_NUMERIC_NUMBERS` to allow\\\\n at [Source: (org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$UnCloseableInputStream); line: 1, column: 88]\",\"code\":400,\"data\":null,\"sdk_error_code\":0}'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Error: nan\n",
      "Saving Model on ../../models/residual/Attention_base-Batch256-LossADAM_MSE-Cluster3 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch256-LossADAM_MSE-Cluster3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch256-LossADAM_MSE-Cluster3/assets\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/c2032ed5d0b940bf9eca684528f56536\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     batch_loss          : nan\n",
      "COMET INFO:     epoch_duration [10] : (18.72516569199979, 23.93002397700002)\n",
      "COMET INFO:     loss                : nan\n",
      "COMET INFO:     val_loss            : nan\n",
      "COMET INFO:     validate_batch_loss : nan\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Name             : Attention_base-Batch256-LossADAM_MSE-Cluster3\n",
      "COMET INFO:     test-error       : nan\n",
      "COMET INFO:     trainable_params : 240131\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad                 : False\n",
      "COMET INFO:     Adam_beta_1                  : 0.9\n",
      "COMET INFO:     Adam_beta_2                  : 0.999\n",
      "COMET INFO:     Adam_clipnorm                : 1\n",
      "COMET INFO:     Adam_clipvalue               : 1\n",
      "COMET INFO:     Adam_ema_momentum            : 0.99\n",
      "COMET INFO:     Adam_ema_overwrite_frequency : 1\n",
      "COMET INFO:     Adam_epsilon                 : 1e-07\n",
      "COMET INFO:     Adam_global_clipnorm         : 1\n",
      "COMET INFO:     Adam_is_legacy_optimizer     : False\n",
      "COMET INFO:     Adam_jit_compile             : False\n",
      "COMET INFO:     Adam_learning_rate           : 0.0010000000474974513\n",
      "COMET INFO:     Adam_name                    : Adam\n",
      "COMET INFO:     Adam_use_ema                 : False\n",
      "COMET INFO:     Adam_weight_decay            : 1\n",
      "COMET INFO:     epochs                       : 50\n",
      "COMET INFO:     steps                        : 2668\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (279.30 KB)\n",
      "COMET INFO:     histogram3d              : 19\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     model-element            : 5 (3.03 MB)\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: \n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET INFO: Uploading 56 metrics, params and output messages\n",
      "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
      "COMET INFO: The Python SDK has 10800 seconds to finish uploading collected data\n",
      "COMET INFO: Still uploading 3 file(s), remaining 2.61 MB/3.26 MB\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Running Cluster_id: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/35f1b74a338644e19e14ee3183f3bc41\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Experiment Attention_base-Batch256-LossADAM_MSE-Cluster4:\n",
      "\n",
      "Getting data..\n",
      "Rows: 50578\n",
      "\n",
      "Preparing data..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2bc435278094a609e37c070e2d6d0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating dataset..\n",
      "Train dataset: 30752, Val dataset: 13056, Test dataset: 6770\n",
      "\n",
      "Defining & Training model..\n",
      "Model: \"model_95\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 1, 56)]      0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 1, 56)       232504      ['input_5[0][0]',                \n",
      " eadAttention)                                                    'input_5[0][0]',                \n",
      "                                                                  'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 1, 512)       29184       ['multi_head_attention_4[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 512)          0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 64)           32832       ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 64)           0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 128)          8320        ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 128)          0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1)            129         ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 302,969\n",
      "Trainable params: 302,969\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "961/961 [==============================] - 11s 10ms/step - loss: 0.0102 - val_loss: 0.0013\n",
      "Epoch 2/50\n",
      "961/961 [==============================] - 10s 10ms/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 3/50\n",
      "961/961 [==============================] - 10s 10ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 4/50\n",
      "961/961 [==============================] - 11s 11ms/step - loss: 0.0012 - val_loss: 9.0692e-04\n",
      "Epoch 5/50\n",
      "961/961 [==============================] - 11s 11ms/step - loss: 0.0011 - val_loss: 8.2671e-04\n",
      "Epoch 6/50\n",
      "961/961 [==============================] - 9s 9ms/step - loss: 0.0011 - val_loss: 9.9739e-04\n",
      "Epoch 7/50\n",
      "961/961 [==============================] - 9s 9ms/step - loss: 0.0013 - val_loss: 8.0148e-04\n",
      "Epoch 8/50\n",
      "961/961 [==============================] - 8s 9ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "961/961 [==============================] - 9s 9ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "961/961 [==============================] - 9s 9ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 11/50\n",
      "961/961 [==============================] - 10s 10ms/step - loss: 0.0011 - val_loss: 8.7913e-04\n",
      "Epoch 12/50\n",
      "961/961 [==============================] - 9s 9ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 13/50\n",
      "961/961 [==============================] - 12s 12ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 14/50\n",
      "961/961 [==============================] - 14s 14ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 15/50\n",
      "961/961 [==============================] - 11s 12ms/step - loss: 0.0012 - val_loss: 9.6243e-04\n",
      "Epoch 16/50\n",
      "961/961 [==============================] - 11s 11ms/step - loss: 0.0011 - val_loss: 9.1726e-04\n",
      "Epoch 17/50\n",
      "960/961 [============================>.] - ETA: 0s - loss: 0.0012Restoring model weights from the end of the best epoch: 7.\n",
      "961/961 [==============================] - 11s 11ms/step - loss: 0.0012 - val_loss: 9.1841e-04\n",
      "Epoch 17: early stopping\n",
      "212/212 [==============================] - 1s 3ms/step\n",
      "Final Error: 0.019130663982291927\n",
      "Saving Model on ../../models/residual/Attention_base-Batch256-LossADAM_MSE-Cluster4 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch256-LossADAM_MSE-Cluster4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch256-LossADAM_MSE-Cluster4/assets\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/35f1b74a338644e19e14ee3183f3bc41\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     batch_loss [1649]         : (0.00016176614735741168, 0.1629139482975006)\n",
      "COMET INFO:     epoch_duration [17]       : (8.253019323999979, 13.546077043999958)\n",
      "COMET INFO:     loss [17]                 : (0.0010953552555292845, 0.010227671824395657)\n",
      "COMET INFO:     val_loss [17]             : (0.0008014772902242839, 0.0014504181453958154)\n",
      "COMET INFO:     validate_batch_loss [697] : (4.636749508790672e-05, 0.001674237777478993)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Name             : Attention_base-Batch256-LossADAM_MSE-Cluster4\n",
      "COMET INFO:     test-error       : 0.019130663982291927\n",
      "COMET INFO:     trainable_params : 302969\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad                 : False\n",
      "COMET INFO:     Adam_beta_1                  : 0.9\n",
      "COMET INFO:     Adam_beta_2                  : 0.999\n",
      "COMET INFO:     Adam_clipnorm                : 1\n",
      "COMET INFO:     Adam_clipvalue               : 1\n",
      "COMET INFO:     Adam_ema_momentum            : 0.99\n",
      "COMET INFO:     Adam_ema_overwrite_frequency : 1\n",
      "COMET INFO:     Adam_epsilon                 : 1e-07\n",
      "COMET INFO:     Adam_global_clipnorm         : 1\n",
      "COMET INFO:     Adam_is_legacy_optimizer     : False\n",
      "COMET INFO:     Adam_jit_compile             : False\n",
      "COMET INFO:     Adam_learning_rate           : 0.0010000000474974513\n",
      "COMET INFO:     Adam_name                    : Adam\n",
      "COMET INFO:     Adam_use_ema                 : False\n",
      "COMET INFO:     Adam_weight_decay            : 1\n",
      "COMET INFO:     epochs                       : 50\n",
      "COMET INFO:     steps                        : 961\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (297.87 KB)\n",
      "COMET INFO:     histogram3d              : 342\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     model-element            : 5 (3.75 MB)\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: \n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Running Cluster_id: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/83581c0651a84fc59a4467030778299f\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Experiment Attention_base-Batch512-LossADAM_MSE-Cluster5:\n",
      "\n",
      "Getting data..\n",
      "Rows: 92505\n",
      "\n",
      "Preparing data..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ad46cc25284e9cba4ec5e0c8b631cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating dataset..\n",
      "Train dataset: 55487, Val dataset: 24524, Test dataset: 12437\n",
      "\n",
      "Defining & Training model..\n",
      "Model: \"model_114\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 1, 59)]      0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 1, 59)       122427      ['input_6[0][0]',                \n",
      " eadAttention)                                                    'input_6[0][0]',                \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 1, 512)       30720       ['multi_head_attention_5[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 512)          0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 512)          262656      ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 512)          0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 512)          262656      ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 512)          0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 1)            513         ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 678,972\n",
      "Trainable params: 678,972\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "1734/1734 [==============================] - 36s 20ms/step - loss: 0.0011 - val_loss: 4.2746e-04\n",
      "Epoch 2/50\n",
      "1734/1734 [==============================] - 32s 18ms/step - loss: 5.2335e-04 - val_loss: 3.3654e-04\n",
      "Epoch 3/50\n",
      "1734/1734 [==============================] - 29s 17ms/step - loss: 4.8114e-04 - val_loss: 2.8662e-04\n",
      "Epoch 4/50\n",
      "1734/1734 [==============================] - 32s 18ms/step - loss: 4.4498e-04 - val_loss: 2.7399e-04\n",
      "Epoch 5/50\n",
      "1734/1734 [==============================] - 32s 18ms/step - loss: 1.1510 - val_loss: 0.0011\n",
      "Epoch 6/50\n",
      "1734/1734 [==============================] - 39s 23ms/step - loss: 0.0028 - val_loss: 4.3504e-04\n",
      "Epoch 7/50\n",
      "1734/1734 [==============================] - 34s 20ms/step - loss: 9.7280e-04 - val_loss: 3.1532e-04\n",
      "Epoch 8/50\n",
      "1734/1734 [==============================] - 39s 23ms/step - loss: 6.0243e-04 - val_loss: 2.6492e-04\n",
      "Epoch 9/50\n",
      "1734/1734 [==============================] - 28s 16ms/step - loss: 4.9139e-04 - val_loss: 3.5844e-04\n",
      "Epoch 10/50\n",
      "1734/1734 [==============================] - 33s 19ms/step - loss: 4.4410e-04 - val_loss: 2.9471e-04\n",
      "Epoch 11/50\n",
      "1734/1734 [==============================] - 36s 21ms/step - loss: 4.1319e-04 - val_loss: 2.6686e-04\n",
      "Epoch 12/50\n",
      "1734/1734 [==============================] - 39s 23ms/step - loss: 4.0158e-04 - val_loss: 2.5678e-04\n",
      "Epoch 13/50\n",
      "1734/1734 [==============================] - 41s 23ms/step - loss: 3.9590e-04 - val_loss: 2.6108e-04\n",
      "Epoch 14/50\n",
      "1734/1734 [==============================] - 35s 20ms/step - loss: 4.1106e-04 - val_loss: 4.3323e-04\n",
      "Epoch 15/50\n",
      "1734/1734 [==============================] - 38s 22ms/step - loss: 0.4896 - val_loss: 7.7615e-04\n",
      "Epoch 16/50\n",
      "1734/1734 [==============================] - 44s 26ms/step - loss: 0.0013 - val_loss: 3.9205e-04\n",
      "Epoch 17/50\n",
      "1734/1734 [==============================] - 48s 27ms/step - loss: 6.5359e-04 - val_loss: 2.6630e-04\n",
      "Epoch 18/50\n",
      "1734/1734 [==============================] - 47s 27ms/step - loss: 5.1569e-04 - val_loss: 2.5850e-04\n",
      "Epoch 19/50\n",
      "1734/1734 [==============================] - 39s 23ms/step - loss: 4.3189e-04 - val_loss: 3.6764e-04\n",
      "Epoch 20/50\n",
      "1734/1734 [==============================] - 43s 25ms/step - loss: 4.3117e-04 - val_loss: 2.7783e-04\n",
      "Epoch 21/50\n",
      "1734/1734 [==============================] - 50s 29ms/step - loss: 4.1228e-04 - val_loss: 2.6468e-04\n",
      "Epoch 22/50\n",
      "1734/1734 [==============================] - ETA: 0s - loss: 4.1818e-04Restoring model weights from the end of the best epoch: 12.\n",
      "1734/1734 [==============================] - 42s 24ms/step - loss: 4.1818e-04 - val_loss: 3.3857e-04\n",
      "Epoch 22: early stopping\n",
      "389/389 [==============================] - 2s 4ms/step\n",
      "Final Error: 0.00790949395723526\n",
      "Saving Model on ../../models/residual/Attention_base-Batch512-LossADAM_MSE-Cluster5 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch512-LossADAM_MSE-Cluster5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch512-LossADAM_MSE-Cluster5/assets\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/83581c0651a84fc59a4467030778299f\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     batch_loss [3828]          : (6.719335942761973e-05, 1.3888969421386719)\n",
      "COMET INFO:     epoch_duration [22]        : (27.558520242999748, 49.67450154900007)\n",
      "COMET INFO:     loss [22]                  : (0.0003959027526434511, 1.15104079246521)\n",
      "COMET INFO:     val_loss [22]              : (0.0002567848132457584, 0.0011303452774882317)\n",
      "COMET INFO:     validate_batch_loss [1694] : (1.9630149381555384e-06, 0.0011761941714212298)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Name             : Attention_base-Batch512-LossADAM_MSE-Cluster5\n",
      "COMET INFO:     test-error       : 0.00790949395723526\n",
      "COMET INFO:     trainable_params : 678972\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad                 : False\n",
      "COMET INFO:     Adam_beta_1                  : 0.9\n",
      "COMET INFO:     Adam_beta_2                  : 0.999\n",
      "COMET INFO:     Adam_clipnorm                : 1\n",
      "COMET INFO:     Adam_clipvalue               : 1\n",
      "COMET INFO:     Adam_ema_momentum            : 0.99\n",
      "COMET INFO:     Adam_ema_overwrite_frequency : 1\n",
      "COMET INFO:     Adam_epsilon                 : 1e-07\n",
      "COMET INFO:     Adam_global_clipnorm         : 1\n",
      "COMET INFO:     Adam_is_legacy_optimizer     : False\n",
      "COMET INFO:     Adam_jit_compile             : False\n",
      "COMET INFO:     Adam_learning_rate           : 0.0010000000474974513\n",
      "COMET INFO:     Adam_name                    : Adam\n",
      "COMET INFO:     Adam_use_ema                 : False\n",
      "COMET INFO:     Adam_weight_decay            : 1\n",
      "COMET INFO:     epochs                       : 50\n",
      "COMET INFO:     steps                        : 1734\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (313.06 KB)\n",
      "COMET INFO:     histogram3d              : 437\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     model-element            : 5 (8.05 MB)\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: \n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Running Cluster_id: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/6bf9f8ee5fd44f568db3a6d6a9560d5f\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Experiment Attention_base-Batch256-LossADAM_MSE-Cluster6:\n",
      "\n",
      "Getting data..\n",
      "Rows: 83587\n",
      "\n",
      "Preparing data..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb7e6cd7d614d56b0bea733b350b366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating dataset..\n",
      "Train dataset: 51074, Val dataset: 21549, Test dataset: 10964\n",
      "\n",
      "Defining & Training model..\n",
      "Model: \"model_138\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 1, 65)]      0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 1, 65)       134721      ['input_7[0][0]',                \n",
      " eadAttention)                                                    'input_7[0][0]',                \n",
      "                                                                  'input_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 1, 128)       8448        ['multi_head_attention_6[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 128)          0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 256)          33024       ['flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 256)          0           ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 256)          65792       ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 256)          0           ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 1)            257         ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 242,242\n",
      "Trainable params: 242,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "1597/1597 [==============================] - 21s 12ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 2/50\n",
      "1597/1597 [==============================] - 21s 13ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 3/50\n",
      "1597/1597 [==============================] - 16s 10ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 4/50\n",
      "1597/1597 [==============================] - 16s 10ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 5/50\n",
      "1597/1597 [==============================] - 13s 8ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 6/50\n",
      "1597/1597 [==============================] - 12s 8ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 7/50\n",
      "1597/1597 [==============================] - 12s 7ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 8/50\n",
      "1597/1597 [==============================] - 12s 7ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 9/50\n",
      "1597/1597 [==============================] - 12s 8ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 10/50\n",
      "1597/1597 [==============================] - 13s 8ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 11/50\n",
      "1597/1597 [==============================] - 12s 8ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 12/50\n",
      "1597/1597 [==============================] - 12s 8ms/step - loss: 0.0013 - val_loss: 9.9980e-04\n",
      "Epoch 13/50\n",
      "1597/1597 [==============================] - 12s 8ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 14/50\n",
      "1597/1597 [==============================] - 12s 8ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 15/50\n",
      "1597/1597 [==============================] - 13s 8ms/step - loss: 0.0013 - val_loss: 9.7725e-04\n",
      "Epoch 16/50\n",
      "1597/1597 [==============================] - 22s 14ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 17/50\n",
      "1597/1597 [==============================] - 23s 14ms/step - loss: 0.0013 - val_loss: 9.8966e-04\n",
      "Epoch 18/50\n",
      "1597/1597 [==============================] - 20s 13ms/step - loss: 0.0013 - val_loss: 9.7606e-04\n",
      "Epoch 19/50\n",
      "1597/1597 [==============================] - 16s 10ms/step - loss: 0.0013 - val_loss: 9.9042e-04\n",
      "Epoch 20/50\n",
      "1597/1597 [==============================] - 27s 17ms/step - loss: 0.0013 - val_loss: 9.4780e-04\n",
      "Epoch 21/50\n",
      "1597/1597 [==============================] - 23s 15ms/step - loss: 0.0013 - val_loss: 9.4575e-04\n",
      "Epoch 22/50\n",
      "1597/1597 [==============================] - 27s 17ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 23/50\n",
      "1597/1597 [==============================] - 29s 18ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 24/50\n",
      "1597/1597 [==============================] - 21s 13ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 25/50\n",
      "1597/1597 [==============================] - 22s 14ms/step - loss: 0.0013 - val_loss: 9.6911e-04\n",
      "Epoch 26/50\n",
      "1597/1597 [==============================] - 28s 18ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 27/50\n",
      "1597/1597 [==============================] - 17s 11ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 28/50\n",
      "1597/1597 [==============================] - 20s 12ms/step - loss: 0.0013 - val_loss: 9.4822e-04\n",
      "Epoch 29/50\n",
      "1597/1597 [==============================] - 21s 13ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 30/50\n",
      "1597/1597 [==============================] - 24s 15ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 31/50\n",
      "1595/1597 [============================>.] - ETA: 0s - loss: 0.0013Restoring model weights from the end of the best epoch: 21.\n",
      "1597/1597 [==============================] - 29s 18ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 31: early stopping\n",
      "343/343 [==============================] - 2s 4ms/step\n",
      "Final Error: 0.015652987825760165\n",
      "Saving Model on ../../models/residual/Attention_base-Batch256-LossADAM_MSE-Cluster6 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch256-LossADAM_MSE-Cluster6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch256-LossADAM_MSE-Cluster6/assets\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/6bf9f8ee5fd44f568db3a6d6a9560d5f\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     batch_loss [4960]          : (0.00020187674090266228, 0.07815229147672653)\n",
      "COMET INFO:     epoch_duration [31]        : (11.508829957000671, 28.438147238000056)\n",
      "COMET INFO:     loss [31]                  : (0.0012749935267493129, 0.0026974279899150133)\n",
      "COMET INFO:     val_loss [31]              : (0.0009457450360059738, 0.001685073133558035)\n",
      "COMET INFO:     validate_batch_loss [2108] : (0.0002294881414854899, 0.00351782888174057)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Name             : Attention_base-Batch256-LossADAM_MSE-Cluster6\n",
      "COMET INFO:     test-error       : 0.015652987825760165\n",
      "COMET INFO:     trainable_params : 242242\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad                 : False\n",
      "COMET INFO:     Adam_beta_1                  : 0.9\n",
      "COMET INFO:     Adam_beta_2                  : 0.999\n",
      "COMET INFO:     Adam_clipnorm                : 1\n",
      "COMET INFO:     Adam_clipvalue               : 1\n",
      "COMET INFO:     Adam_ema_momentum            : 0.99\n",
      "COMET INFO:     Adam_ema_overwrite_frequency : 1\n",
      "COMET INFO:     Adam_epsilon                 : 1e-07\n",
      "COMET INFO:     Adam_global_clipnorm         : 1\n",
      "COMET INFO:     Adam_is_legacy_optimizer     : False\n",
      "COMET INFO:     Adam_jit_compile             : False\n",
      "COMET INFO:     Adam_learning_rate           : 0.0010000000474974513\n",
      "COMET INFO:     Adam_name                    : Adam\n",
      "COMET INFO:     Adam_use_ema                 : False\n",
      "COMET INFO:     Adam_weight_decay            : 1\n",
      "COMET INFO:     epochs                       : 50\n",
      "COMET INFO:     steps                        : 1597\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (325.28 KB)\n",
      "COMET INFO:     histogram3d              : 608\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     model-element            : 5 (3.06 MB)\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: \n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Running Cluster_id: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/c347a8bb750a40b5a3083aa45d5c00df\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Experiment Attention_base-Batch512-LossADAM_MSE-Cluster7:\n",
      "\n",
      "Getting data..\n",
      "Rows: 65540\n",
      "\n",
      "Preparing data..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a5a353d7654773a2c2fb5236c8b56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating dataset..\n",
      "Train dataset: 39288, Val dataset: 17203, Test dataset: 9049\n",
      "\n",
      "Defining & Training model..\n",
      "Model: \"model_171\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 1, 60)]      0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 1, 60)       124476      ['input_8[0][0]',                \n",
      " eadAttention)                                                    'input_8[0][0]',                \n",
      "                                                                  'input_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 1, 128)       7808        ['multi_head_attention_7[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)            (None, 128)          0           ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 256)          33024       ['flatten_7[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 256)          0           ['dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 512)          131584      ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 512)          0           ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 1)            513         ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 297,405\n",
      "Trainable params: 297,405\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "1228/1228 [==============================] - 13s 9ms/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 2/50\n",
      "1228/1228 [==============================] - 17s 14ms/step - loss: 0.0012 - val_loss: 8.0835e-04\n",
      "Epoch 3/50\n",
      "1228/1228 [==============================] - 16s 13ms/step - loss: 0.0011 - val_loss: 9.2394e-04\n",
      "Epoch 4/50\n",
      "1228/1228 [==============================] - 13s 11ms/step - loss: 0.0012 - val_loss: 7.8109e-04\n",
      "Epoch 5/50\n",
      "1228/1228 [==============================] - 13s 11ms/step - loss: 0.0012 - val_loss: 8.4165e-04\n",
      "Epoch 6/50\n",
      "1228/1228 [==============================] - 14s 11ms/step - loss: 0.0012 - val_loss: 7.7277e-04\n",
      "Epoch 7/50\n",
      "1228/1228 [==============================] - 11s 9ms/step - loss: 0.0012 - val_loss: 8.8004e-04\n",
      "Epoch 8/50\n",
      "1228/1228 [==============================] - 11s 9ms/step - loss: 0.0012 - val_loss: 8.8726e-04\n",
      "Epoch 9/50\n",
      "1228/1228 [==============================] - 15s 12ms/step - loss: 0.0012 - val_loss: 7.4375e-04\n",
      "Epoch 10/50\n",
      "1228/1228 [==============================] - 12s 9ms/step - loss: 0.0012 - val_loss: 8.6555e-04\n",
      "Epoch 11/50\n",
      "1228/1228 [==============================] - 16s 13ms/step - loss: 0.0011 - val_loss: 7.4605e-04\n",
      "Epoch 12/50\n",
      "1228/1228 [==============================] - 16s 13ms/step - loss: 0.0011 - val_loss: 8.9108e-04\n",
      "Epoch 13/50\n",
      "1228/1228 [==============================] - 17s 14ms/step - loss: 0.0011 - val_loss: 8.1505e-04\n",
      "Epoch 14/50\n",
      "1228/1228 [==============================] - 14s 11ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 15/50\n",
      "1228/1228 [==============================] - 11s 9ms/step - loss: 0.0011 - val_loss: 7.7768e-04\n",
      "Epoch 16/50\n",
      "1228/1228 [==============================] - 11s 9ms/step - loss: 0.0011 - val_loss: 7.5452e-04\n",
      "Epoch 17/50\n",
      "1228/1228 [==============================] - 11s 9ms/step - loss: 0.0011 - val_loss: 8.0885e-04\n",
      "Epoch 18/50\n",
      "1228/1228 [==============================] - 13s 11ms/step - loss: 0.0011 - val_loss: 9.5876e-04\n",
      "Epoch 19/50\n",
      "1228/1228 [==============================] - ETA: 0s - loss: 0.0011Restoring model weights from the end of the best epoch: 9.\n",
      "1228/1228 [==============================] - 12s 9ms/step - loss: 0.0011 - val_loss: 7.6915e-04\n",
      "Epoch 19: early stopping\n",
      "283/283 [==============================] - 1s 3ms/step\n",
      "Final Error: 0.017432682770305935\n",
      "Saving Model on ../../models/residual/Attention_base-Batch512-LossADAM_MSE-Cluster7 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch512-LossADAM_MSE-Cluster7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch512-LossADAM_MSE-Cluster7/assets\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/c347a8bb750a40b5a3083aa45d5c00df\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     batch_loss [2337]          : (0.00013067497638985515, 0.06869194656610489)\n",
      "COMET INFO:     epoch_duration [19]        : (10.640966228999787, 16.69634211599987)\n",
      "COMET INFO:     loss [19]                  : (0.0011137374676764011, 0.0037200385704636574)\n",
      "COMET INFO:     val_loss [19]              : (0.0007437484455294907, 0.001208884292282164)\n",
      "COMET INFO:     validate_batch_loss [1026] : (3.7036888898001052e-06, 0.001339772017672658)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Name             : Attention_base-Batch512-LossADAM_MSE-Cluster7\n",
      "COMET INFO:     test-error       : 0.017432682770305935\n",
      "COMET INFO:     trainable_params : 297405\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad                 : False\n",
      "COMET INFO:     Adam_beta_1                  : 0.9\n",
      "COMET INFO:     Adam_beta_2                  : 0.999\n",
      "COMET INFO:     Adam_clipnorm                : 1\n",
      "COMET INFO:     Adam_clipvalue               : 1\n",
      "COMET INFO:     Adam_ema_momentum            : 0.99\n",
      "COMET INFO:     Adam_ema_overwrite_frequency : 1\n",
      "COMET INFO:     Adam_epsilon                 : 1e-07\n",
      "COMET INFO:     Adam_global_clipnorm         : 1\n",
      "COMET INFO:     Adam_is_legacy_optimizer     : False\n",
      "COMET INFO:     Adam_jit_compile             : False\n",
      "COMET INFO:     Adam_learning_rate           : 0.0010000000474974513\n",
      "COMET INFO:     Adam_name                    : Adam\n",
      "COMET INFO:     Adam_use_ema                 : False\n",
      "COMET INFO:     Adam_weight_decay            : 1\n",
      "COMET INFO:     epochs                       : 50\n",
      "COMET INFO:     steps                        : 1228\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (343.53 KB)\n",
      "COMET INFO:     histogram3d              : 380\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     model-element            : 5 (3.69 MB)\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: \n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Running Cluster_id: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/141353b5feb947489b5667b0add17b9a\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Experiment Attention_base-Batch256-LossADAM_MSE-Cluster8:\n",
      "\n",
      "Getting data..\n",
      "Rows: 23771\n",
      "\n",
      "Preparing data..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7592f34f9f0344bb888fb346a9a020cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating dataset..\n",
      "Train dataset: 14113, Val dataset: 6536, Test dataset: 3122\n",
      "\n",
      "Defining & Training model..\n",
      "Model: \"model_192\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 1, 54)]      0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 1, 54)       224310      ['input_9[0][0]',                \n",
      " eadAttention)                                                    'input_9[0][0]',                \n",
      "                                                                  'input_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 1, 64)        3520        ['multi_head_attention_8[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)            (None, 64)           0           ['dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 128)          8320        ['flatten_8[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 128)          0           ['dense_33[0][0]']               \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 64)           8256        ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 64)           0           ['dense_34[0][0]']               \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 1)            65          ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 244,471\n",
      "Trainable params: 244,471\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "442/442 [==============================] - 5s 7ms/step - loss: 0.0117 - val_loss: 0.0013\n",
      "Epoch 2/50\n",
      "442/442 [==============================] - 3s 8ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 3/50\n",
      "442/442 [==============================] - 4s 8ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 4/50\n",
      "442/442 [==============================] - 4s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 5/50\n",
      "442/442 [==============================] - 4s 9ms/step - loss: 8.8630e-04 - val_loss: 0.0013\n",
      "Epoch 6/50\n",
      "442/442 [==============================] - 4s 9ms/step - loss: 8.0510e-04 - val_loss: 0.0010\n",
      "Epoch 7/50\n",
      "442/442 [==============================] - 5s 10ms/step - loss: 6.3721e-04 - val_loss: 0.0012\n",
      "Epoch 8/50\n",
      "442/442 [==============================] - 6s 13ms/step - loss: 6.3414e-04 - val_loss: 9.5531e-04\n",
      "Epoch 9/50\n",
      "442/442 [==============================] - 5s 12ms/step - loss: 5.7121e-04 - val_loss: 0.0010\n",
      "Epoch 10/50\n",
      "442/442 [==============================] - 4s 10ms/step - loss: 5.4729e-04 - val_loss: 0.0011\n",
      "Epoch 11/50\n",
      "442/442 [==============================] - 4s 9ms/step - loss: 5.2350e-04 - val_loss: 9.1783e-04\n",
      "Epoch 12/50\n",
      "442/442 [==============================] - 4s 8ms/step - loss: 5.0276e-04 - val_loss: 9.2804e-04\n",
      "Epoch 13/50\n",
      "442/442 [==============================] - 4s 8ms/step - loss: 4.8417e-04 - val_loss: 0.0011\n",
      "Epoch 14/50\n",
      "442/442 [==============================] - 4s 8ms/step - loss: 5.1723e-04 - val_loss: 0.0012\n",
      "Epoch 15/50\n",
      "442/442 [==============================] - 3s 8ms/step - loss: 5.0227e-04 - val_loss: 9.7178e-04\n",
      "Epoch 16/50\n",
      "442/442 [==============================] - 4s 9ms/step - loss: 5.1967e-04 - val_loss: 0.0011\n",
      "Epoch 17/50\n",
      "442/442 [==============================] - 4s 8ms/step - loss: 5.1701e-04 - val_loss: 9.3961e-04\n",
      "Epoch 18/50\n",
      "442/442 [==============================] - 3s 8ms/step - loss: 5.5017e-04 - val_loss: 0.0011\n",
      "Epoch 19/50\n",
      "442/442 [==============================] - 4s 8ms/step - loss: 5.1681e-04 - val_loss: 9.3855e-04\n",
      "Epoch 20/50\n",
      "442/442 [==============================] - 3s 8ms/step - loss: 5.2108e-04 - val_loss: 0.0010\n",
      "Epoch 21/50\n",
      "438/442 [============================>.] - ETA: 0s - loss: 5.1339e-04Restoring model weights from the end of the best epoch: 11.\n",
      "442/442 [==============================] - 4s 9ms/step - loss: 5.1377e-04 - val_loss: 0.0014\n",
      "Epoch 21: early stopping\n",
      "98/98 [==============================] - 0s 3ms/step\n",
      "Final Error: 0.009384017074568214\n",
      "Saving Model on ../../models/residual/Attention_base-Batch256-LossADAM_MSE-Cluster8 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch256-LossADAM_MSE-Cluster8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch256-LossADAM_MSE-Cluster8/assets\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/141353b5feb947489b5667b0add17b9a\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     batch_loss [945]          : (3.382598515599966e-05, 0.15784133970737457)\n",
      "COMET INFO:     epoch_duration [21]       : (3.239731263000067, 5.365948676999324)\n",
      "COMET INFO:     loss [21]                 : (0.00048416529898531735, 0.011741304770112038)\n",
      "COMET INFO:     val_loss [21]             : (0.0009178349864669144, 0.0013545936672016978)\n",
      "COMET INFO:     validate_batch_loss [441] : (8.012332727957983e-06, 0.003063616342842579)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Name             : Attention_base-Batch256-LossADAM_MSE-Cluster8\n",
      "COMET INFO:     test-error       : 0.009384017074568214\n",
      "COMET INFO:     trainable_params : 244471\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad                 : False\n",
      "COMET INFO:     Adam_beta_1                  : 0.9\n",
      "COMET INFO:     Adam_beta_2                  : 0.999\n",
      "COMET INFO:     Adam_clipnorm                : 1\n",
      "COMET INFO:     Adam_clipvalue               : 1\n",
      "COMET INFO:     Adam_ema_momentum            : 0.99\n",
      "COMET INFO:     Adam_ema_overwrite_frequency : 1\n",
      "COMET INFO:     Adam_epsilon                 : 1e-07\n",
      "COMET INFO:     Adam_global_clipnorm         : 1\n",
      "COMET INFO:     Adam_is_legacy_optimizer     : False\n",
      "COMET INFO:     Adam_jit_compile             : False\n",
      "COMET INFO:     Adam_learning_rate           : 0.0010000000474974513\n",
      "COMET INFO:     Adam_name                    : Adam\n",
      "COMET INFO:     Adam_use_ema                 : False\n",
      "COMET INFO:     Adam_weight_decay            : 1\n",
      "COMET INFO:     epochs                       : 50\n",
      "COMET INFO:     steps                        : 442\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (349.40 KB)\n",
      "COMET INFO:     histogram3d              : 418\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     model-element            : 5 (3.08 MB)\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: \n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
      "COMET INFO: The Python SDK has 10800 seconds to finish uploading collected data\n",
      "COMET INFO: All files uploaded, waiting for confirmation they have been all received\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Running Cluster_id: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/2acedad3e5c04dbabf4f33e4806c7026\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Experiment Attention_base-Batch1024-LossADAM_MSE-Cluster9:\n",
      "\n",
      "Getting data..\n",
      "Rows: 136054\n",
      "\n",
      "Preparing data..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb20d38a19c74bb18002679f1a26fb33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating dataset..\n",
      "Train dataset: 82415, Val dataset: 36883, Test dataset: 16756\n",
      "\n",
      "Defining & Training model..\n",
      "Model: \"model_215\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 1, 64)]      0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 1, 64)       265280      ['input_10[0][0]',               \n",
      " eadAttention)                                                    'input_10[0][0]',               \n",
      "                                                                  'input_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_36 (Dense)               (None, 1, 64)        4160        ['multi_head_attention_9[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_9 (Flatten)            (None, 64)           0           ['dense_36[0][0]']               \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 128)          8320        ['flatten_9[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 128)          0           ['dense_37[0][0]']               \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 512)          66048       ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 512)          0           ['dense_38[0][0]']               \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 1)            513         ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 344,321\n",
      "Trainable params: 344,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "2574/2576 [============================>.] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2576/2576 [==============================] - 29s 10ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "2572/2576 [============================>.] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2576/2576 [==============================] - 23s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "2576/2576 [==============================] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2576/2576 [==============================] - 23s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "2575/2576 [============================>.] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2576/2576 [==============================] - 24s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "2574/2576 [============================>.] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2576/2576 [==============================] - 25s 10ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "2570/2576 [============================>.] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2576/2576 [==============================] - 22s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "2573/2576 [============================>.] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2576/2576 [==============================] - 22s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "2574/2576 [============================>.] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2576/2576 [==============================] - 22s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "2576/2576 [==============================] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2576/2576 [==============================] - 23s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "2574/2576 [============================>.] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n",
      "COMET WARNING: ignoring empty histogram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2576/2576 [==============================] - 24s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10: early stopping\n",
      "524/524 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET ERROR: Error sending log other messages, got 400 b'{\"msg\":\"Invalid json format: Non-standard token \\'NaN\\': enable `JsonReadFeature.ALLOW_NON_NUMERIC_NUMBERS` to allow\\\\n at [Source: (org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$UnCloseableInputStream); line: 1, column: 88]\",\"code\":400,\"data\":null,\"sdk_error_code\":0}'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Error: nan\n",
      "Saving Model on ../../models/residual/Attention_base-Batch1024-LossADAM_MSE-Cluster9 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch1024-LossADAM_MSE-Cluster9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/residual/Attention_base-Batch1024-LossADAM_MSE-Cluster9/assets\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------------------------------------------------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.com/pveronesi/arpae-tsd-residual-experiments/2acedad3e5c04dbabf4f33e4806c7026\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     batch_loss          : nan\n",
      "COMET INFO:     epoch_duration [10] : (22.209195063000152, 29.61421117200007)\n",
      "COMET INFO:     loss                : nan\n",
      "COMET INFO:     val_loss            : nan\n",
      "COMET INFO:     validate_batch_loss : nan\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Name             : Attention_base-Batch1024-LossADAM_MSE-Cluster9\n",
      "COMET INFO:     test-error       : nan\n",
      "COMET INFO:     trainable_params : 344321\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad                 : False\n",
      "COMET INFO:     Adam_beta_1                  : 0.9\n",
      "COMET INFO:     Adam_beta_2                  : 0.999\n",
      "COMET INFO:     Adam_clipnorm                : 1\n",
      "COMET INFO:     Adam_clipvalue               : 1\n",
      "COMET INFO:     Adam_ema_momentum            : 0.99\n",
      "COMET INFO:     Adam_ema_overwrite_frequency : 1\n",
      "COMET INFO:     Adam_epsilon                 : 1e-07\n",
      "COMET INFO:     Adam_global_clipnorm         : 1\n",
      "COMET INFO:     Adam_is_legacy_optimizer     : False\n",
      "COMET INFO:     Adam_jit_compile             : False\n",
      "COMET INFO:     Adam_learning_rate           : 0.0010000000474974513\n",
      "COMET INFO:     Adam_name                    : Adam\n",
      "COMET INFO:     Adam_use_ema                 : False\n",
      "COMET INFO:     Adam_weight_decay            : 1\n",
      "COMET INFO:     epochs                       : 50\n",
      "COMET INFO:     steps                        : 2576\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (360.49 KB)\n",
      "COMET INFO:     histogram3d              : 19\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     model-element            : 5 (4.22 MB)\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: \n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
      "COMET INFO: The Python SDK has 10800 seconds to finish uploading collected data\n",
      "COMET INFO: All files uploaded, waiting for confirmation they have been all received\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "if exp_wdgt_value.value == 'Manual Params':\n",
    "    # Set params\n",
    "    TAG = \"\"\n",
    "    sample_cluster_id = DEFAULT_CLUSTER_ID\n",
    "    model_name = DEFAULT_MODEL_NAME\n",
    "    batch_size = DEFAULT_BATCH_SIZE\n",
    "    learning_rate = DEFAULT_LEARNING_RATE\n",
    "    weight_decay = DEFAULT_WEIGHT_DECAY\n",
    "    rho = DEFAULT_RHO    \n",
    "    loss = DEFAULT_LOSS\n",
    "    epochs = DEFAULT_EPOCHS\n",
    "    dropout = DEFAULT_DROPOUT\n",
    "    attn_key_dim = DEFAULT_ATTN_KEY_DIM\n",
    "    layer_dense_1_units = DEFAULT_LAYER_DENSE_1_UNITS\n",
    "    layer_dense_2_units = DEFAULT_LAYER_DENSE_2_UNITS\n",
    "    layer_dense_3_units = DEFAULT_LAYER_DENSE_3_UNITS    \n",
    "    # Run experiment\n",
    "    history, test_X, test_y, test_df, preds, error, feats = _run_experiment(COMET_API_KEY, COMET_WORKSPACE, \n",
    "                                                                          COMET_PROJECT_NAME, data_df, \n",
    "                                                                          clusters_df, sample_cluster_id, TAG, \n",
    "                                                                          model_name, batch_size, \n",
    "                                                                          loss, learning_rate, weight_decay, rho,\n",
    "                                                                          epochs, \n",
    "                                                                          dropout, attn_key_dim, \n",
    "                                                                          layer_dense_1_units, \n",
    "                                                                          layer_dense_2_units, \n",
    "                                                                          layer_dense_3_units,\n",
    "                                                                          ORIGINAL_FEATS, \n",
    "                                                                          METEO_FEATS, POLLEN_FEATS, DATE_COL, \n",
    "                                                                          LABEL_COL, TRAIN_END, VAL_END, TEST_END)\n",
    "    # Save results\n",
    "    results[sample_cluster_id] = {\n",
    "        'history': history,\n",
    "        'test_X': test_X, \n",
    "        'test_y': test_y,\n",
    "        'test_df': test_df, \n",
    "        'preds': preds, \n",
    "        'error': error,\n",
    "        'feats': feats\n",
    "    }\n",
    "    print(\"Done.\")\n",
    "    \n",
    "elif exp_wdgt_value.value == 'Opt Params':\n",
    "    # For each cluster\n",
    "    for cluster_id in clusters:\n",
    "        print(\"Running Cluster_id: {}\".format(cluster_id))\n",
    "        TAG = \"OPT\"        \n",
    "        # Get Cluster Opt params\n",
    "        params = params_df[params_df['cluster_id']==cluster_id]\n",
    "        model_name = params['model_name'].values[0]\n",
    "        batch_size = params['batch_size'].values[0]\n",
    "        learning_rate = params['learning_rate'].values[0]\n",
    "        weight_decay = DEFAULT_WEIGHT_DECAY\n",
    "        rho = DEFAULT_RHO\n",
    "        loss = DEFAULT_LOSS\n",
    "        epochs = DEFAULT_EPOCHS            \n",
    "        dropout = params['dropout'].values[0]\n",
    "        attn_key_dim = params['attention_key_dim'].values[0]\n",
    "        layer_dense_1_units = params['layer_dense_1_units'].values[0]\n",
    "        layer_dense_2_units = params['layer_dense_2_units'].values[0]\n",
    "        layer_dense_3_units = params['layer_dense_3_units'].values[0]        \n",
    "        # Run experiment\n",
    "        history, test_X, test_y, test_df, preds, error, feats = _run_experiment(COMET_API_KEY, COMET_WORKSPACE, \n",
    "                                                                              COMET_PROJECT_NAME, data_df, \n",
    "                                                                              clusters_df, cluster_id, TAG,\n",
    "                                                                              model_name, batch_size, \n",
    "                                                                              loss, learning_rate, \n",
    "                                                                              weight_decay, rho, epochs, \n",
    "                                                                              dropout, attn_key_dim, \n",
    "                                                                              layer_dense_1_units, \n",
    "                                                                              layer_dense_2_units, \n",
    "                                                                              layer_dense_3_units,\n",
    "                                                                              ORIGINAL_FEATS, METEO_FEATS, \n",
    "                                                                              POLLEN_FEATS, DATE_COL, LABEL_COL, \n",
    "                                                                              TRAIN_END, VAL_END, TEST_END)\n",
    "        # Save results\n",
    "        results[cluster_id] = {\n",
    "            'history': history,\n",
    "            'test_X': test_X, \n",
    "            'test_y': test_y,\n",
    "            'test_df': test_df, \n",
    "            'preds': preds, \n",
    "            'error': error,\n",
    "            'feats': feats\n",
    "        }\n",
    "        print(\"Done.\")\n",
    "    \n",
    "else:\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932e5214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72e37787",
   "metadata": {},
   "source": [
    "<h3>4. Evaluate Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19f04bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster_id: 0\n",
      "MSE Error: 0.005795011985895561\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6z/h5gl1rs567sb9kzq90zfly6w0000gv/T/ipykernel_9894/1001749427.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Plot Feat Importances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparams_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcluster_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0m_feats_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feats'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Plot Preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6z/h5gl1rs567sb9kzq90zfly6w0000gv/T/ipykernel_9894/4041452148.py\u001b[0m in \u001b[0;36m_feats_importances\u001b[0;34m(test_X, test_y, feats)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Get baseline error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfeats_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mff_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mff_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mff_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mff_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mff_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mff_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mff_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot History & Preds for each cluster\n",
    "\n",
    "for cluster_id, result in results.items():\n",
    "    print(\"Cluster_id: {}\".format(cluster_id))\n",
    "    print(\"MSE Error: {}\".format(result['error']))\n",
    "    # Plot History\n",
    "    _plot_history(result['history'])\n",
    "\n",
    "    # Plot Feat Importances\n",
    "    params = params_df[params_df['cluster_id']==cluster_id]\n",
    "    _feats_importances(result['test_X'], result['test_y'], result['feats'])\n",
    "\n",
    "    # Plot Preds\n",
    "    _plot_preds(preds, result['test_df'], LABEL_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd6b0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3620990a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98bdd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fa2a31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
